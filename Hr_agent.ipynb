{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa+ObdvQKhBBmRIhOV9pdd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anusree-128/AI-developer-task/blob/main/Hr_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU PyPDF2 python-docx pypdf transformers sentence-transformers scikit-learn\n",
        "!pip install -qU --upgrade langchain-core langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW35v81HIvXy",
        "outputId": "0d96359e-8323-4a3e-a2a4-d4e013578a2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import docx\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "JCpjIrMDIvbR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JobDescription:\n",
        "    def __init__(self, title: str, description: str, requirements: List[str], preferred_skills: List[str] = None):\n",
        "        self.title = title\n",
        "        self.description = description\n",
        "        self.requirements = requirements\n",
        "        self.preferred_skills = preferred_skills or []\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"title\": self.title,\n",
        "            \"description\": self.description,\n",
        "            \"requirements\": self.requirements,\n",
        "            \"preferred_skills\": self.preferred_skills\n",
        "        }\n",
        "\n",
        "class Candidate:\n",
        "    def __init__(self, id: str, name: str, email: str, score: float, summary: str,\n",
        "                 skills: List[str], experience: str, resume_text: str):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.email = email\n",
        "        self.score = score\n",
        "        self.summary = summary\n",
        "        self.skills = skills\n",
        "        self.experience = experience\n",
        "        self.resume_text = resume_text\n",
        "\n",
        "    def display(self):\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"border: 2px solid #e0e0e0; padding: 15px; margin: 10px; border-radius: 10px; background: #f9f9f9;\">\n",
        "            <h3>üë§ {self.name} - Score: {self.score}/100</h3>\n",
        "            <p><strong>üìß Email:</strong> {self.email}</p>\n",
        "            <p><strong>üìã Summary:</strong> {self.summary}</p>\n",
        "            <p><strong>üõ†Ô∏è Skills:</strong> {', '.join(self.skills[:10])}{'...' if len(self.skills) > 10 else ''}</p>\n",
        "            <p><strong>üíº Experience Highlight:</strong> {self.experience[:200]}...</p>\n",
        "        </div>\n",
        "        \"\"\"))"
      ],
      "metadata": {
        "id": "9POhzT1AIvej"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FreeNLPProcessor:\n",
        "    def __init__(self):\n",
        "        print(\"üîÑ Loading free NLP models...\")\n",
        "        try:\n",
        "            # Lightweight model for summarization\n",
        "            self.summarizer = pipeline(\"summarization\",\n",
        "                                     model=\"sshleifer/distilbart-cnn-12-6\",\n",
        "                                     tokenizer=\"sshleifer/distilbart-cnn-12-6\",\n",
        "                                     framework=\"pt\")\n",
        "        except:\n",
        "            self.summarizer = None\n",
        "            print(\"‚ö†Ô∏è Summarization model not available, using fallback methods\")\n",
        "\n",
        "        # Sentence transformer for semantic similarity\n",
        "        try:\n",
        "            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        except:\n",
        "            self.sentence_model = None\n",
        "            print(\"‚ö†Ô∏è Sentence transformer not available, using TF-IDF\")\n",
        "\n",
        "        print(\"‚úÖ NLP models initialized\")"
      ],
      "metadata": {
        "id": "GZBp3T0dIvh8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResumeProcessor:\n",
        "    def __init__(self):\n",
        "        self.nlp_processor = FreeNLPProcessor()\n",
        "        self.skills_keywords = self._load_skills_keywords()\n",
        "\n",
        "    def _load_skills_keywords(self):\n",
        "        \"\"\"Common technical skills for matching\"\"\"\n",
        "        return {\n",
        "            'programming': ['python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'go', 'rust', 'php', 'swift'],\n",
        "            'web': ['html', 'css', 'react', 'angular', 'vue', 'node', 'django', 'flask', 'spring'],\n",
        "            'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform', 'jenkins'],\n",
        "            'database': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle'],\n",
        "            'data': ['pandas', 'numpy', 'tensorflow', 'pytorch', 'scikit', 'matplotlib', 'seaborn'],\n",
        "            'devops': ['git', 'ci/cd', 'ansible', 'chef', 'puppet', 'linux', 'bash']\n",
        "        }\n",
        "\n",
        "    def extract_text(self, file_content, filename):\n",
        "        \"\"\"Extract text from uploaded file\"\"\"\n",
        "        try:\n",
        "            if filename.lower().endswith('.pdf'):\n",
        "                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "                return text\n",
        "            elif filename.lower().endswith(('.docx', '.doc')):\n",
        "                doc = docx.Document(io.BytesIO(file_content))\n",
        "                return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "            else:\n",
        "                return file_content.decode('utf-8')\n",
        "        except Exception as e:\n",
        "            return f\"Error reading file: {str(e)}\"\n",
        "\n",
        "    def extract_info_regex(self, text):\n",
        "        \"\"\"Extract basic info using regex patterns\"\"\"\n",
        "        # Extract name (simple pattern)\n",
        "        name_match = re.search(r'([A-Z][a-z]+ [A-Z][a-z]+)', text[:500])\n",
        "        name = name_match.group(1) if name_match else \"Unknown Candidate\"\n",
        "\n",
        "        # Extract email\n",
        "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', text)\n",
        "        email = email_match.group() if email_match else \"no-email@example.com\"\n",
        "\n",
        "        return name, email\n",
        "\n",
        "    def extract_skills(self, text):\n",
        "        \"\"\"Extract skills using keyword matching\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_skills = []\n",
        "\n",
        "        for category, skills in self.skills_keywords.items():\n",
        "            for skill in skills:\n",
        "                if skill in text_lower:\n",
        "                    found_skills.append(skill)\n",
        "\n",
        "        return list(set(found_skills))  # Remove duplicates\n",
        "\n",
        "    def calculate_score(self, resume_text, job_description):\n",
        "        \"\"\"Calculate match score using TF-IDF or semantic similarity\"\"\"\n",
        "        # Combine job requirements\n",
        "        job_text = f\"{job_description.title} {job_description.description} {' '.join(job_description.requirements)}\"\n",
        "\n",
        "        if self.nlp_processor.sentence_model:\n",
        "            # Use sentence transformers for better semantic matching\n",
        "            resume_embedding = self.nlp_processor.sentence_model.encode(resume_text, convert_to_tensor=True)\n",
        "            job_embedding = self.nlp_processor.sentence_model.encode(job_text, convert_to_tensor=True)\n",
        "            similarity = util.pytorch_cos_sim(resume_embedding, job_embedding).item()\n",
        "            score = min(100, max(0, similarity * 100))\n",
        "        else:\n",
        "            # Fallback to TF-IDF\n",
        "            vectorizer = TfidfVectorizer().fit_transform([resume_text, job_text])\n",
        "            similarity = cosine_similarity(vectorizer[0:1], vectorizer[1:2])[0][0]\n",
        "            score = min(100, max(0, similarity * 100))\n",
        "\n",
        "        return round(score, 1)\n",
        "\n",
        "    def generate_summary(self, resume_text, job_description):\n",
        "        \"\"\"Generate candidate summary\"\"\"\n",
        "        try:\n",
        "            if self.nlp_processor.summarizer:\n",
        "                # Use the summarization model\n",
        "                summary = self.nlp_processor.summarizer(\n",
        "                    resume_text[:1024],  # Limit input length\n",
        "                    max_length=150,\n",
        "                    min_length=30,\n",
        "                    do_sample=False\n",
        "                )[0]['summary_text']\n",
        "                return summary\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Fallback: extract first few sentences\n",
        "        sentences = re.split(r'[.!?]+', resume_text)\n",
        "        meaningful_sentences = [s.strip() for s in sentences if len(s.split()) > 5]\n",
        "        return \" \".join(meaningful_sentences[:3]) if meaningful_sentences else \"Experience summary not available\"\n",
        "\n",
        "    def process_resume(self, file_content, filename, job_description):\n",
        "        \"\"\"Process a single resume and return candidate data\"\"\"\n",
        "        # Extract text\n",
        "        resume_text = self.extract_text(file_content, filename)\n",
        "        if resume_text.startswith(\"Error\"):\n",
        "            print(f\"‚ùå Error processing {filename}: {resume_text}\")\n",
        "            return None\n",
        "\n",
        "        # Extract basic info\n",
        "        name, email = self.extract_info_regex(resume_text)\n",
        "\n",
        "        # Extract skills\n",
        "        skills = self.extract_skills(resume_text)\n",
        "\n",
        "        # Calculate score\n",
        "        score = self.calculate_score(resume_text, job_description)\n",
        "\n",
        "        # Generate summary\n",
        "        summary = self.generate_summary(resume_text, job_description)\n",
        "\n",
        "        # Extract experience highlight\n",
        "        experience = self._extract_experience_highlight(resume_text)\n",
        "\n",
        "        # Create Candidate object\n",
        "        candidate_id = f\"{name.lower().replace(' ', '_')}_{datetime.now().timestamp()}\"\n",
        "\n",
        "        return Candidate(\n",
        "            id=candidate_id,\n",
        "            name=name,\n",
        "            email=email,\n",
        "            score=score,\n",
        "            summary=summary,\n",
        "            skills=skills,\n",
        "            experience=experience,\n",
        "            resume_text=resume_text\n",
        "        )\n",
        "\n",
        "    def _extract_experience_highlight(self, text):\n",
        "        \"\"\"Extract experience-related text\"\"\"\n",
        "        # Look for experience section\n",
        "        experience_patterns = [\n",
        "            r'experience.*?(\\n.*?){5}',\n",
        "            r'work history.*?(\\n.*?){5}',\n",
        "            r'professional.*?(\\n.*?){5}'\n",
        "        ]\n",
        "\n",
        "        for pattern in experience_patterns:\n",
        "            match = re.search(pattern, text.lower())\n",
        "            if match:\n",
        "                return match.group(0)[:300] + \"...\"\n",
        "\n",
        "        # Fallback: take first 200 characters\n",
        "        return text[:200] + \"...\""
      ],
      "metadata": {
        "id": "Wp-8mMxmIvlm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_title = \"AI develpoer\"\n",
        "job_description_text = \"We are seeking a skilled AI Developer to design, develop, and deploy artificial intelligence solutions. The ideal candidate will have strong expertise in machine learning, deep learning, and software development, with a passion for creating intelligent systems that solve complex problems.\"\n",
        "job_requirements = \"Python programming, Machine Learning, Deep Learning, TensorFlow, PyTorch, Natural Language Processing, Data Preprocessing, Cloud platforms, Git version control, API development\"\n",
        "\n",
        "# Create JobDescription object\n",
        "jd = JobDescription(\n",
        "    title=job_title,\n",
        "    description=job_description_text,\n",
        "    requirements=[req.strip() for req in job_requirements.split(\",\")]\n",
        ")\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"background: #e3f2fd; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
        "    <h2>üéØ Job Description Loaded</h2>\n",
        "    <p><strong>Title:</strong> {jd.title}</p>\n",
        "    <p><strong>Description:</strong> {jd.description}</p>\n",
        "    <p><strong>Requirements:</strong> {', '.join(jd.requirements)}</p>\n",
        "</div>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "PYLzAiZgIvrK",
        "outputId": "61719c16-5cc8-4ebb-e6e1-8e81e6110517"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"background: #e3f2fd; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
              "    <h2>üéØ Job Description Loaded</h2>\n",
              "    <p><strong>Title:</strong> AI develpoer</p>\n",
              "    <p><strong>Description:</strong> We are seeking a skilled AI Developer to design, develop, and deploy artificial intelligence solutions. The ideal candidate will have strong expertise in machine learning, deep learning, and software development, with a passion for creating intelligent systems that solve complex problems.</p>\n",
              "    <p><strong>Requirements:</strong> Python programming, Machine Learning, Deep Learning, TensorFlow, PyTorch, Natural Language Processing, Data Preprocessing, Cloud platforms, Git version control, API development</p>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÅ Please upload resume files (PDF or DOCX):\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "if not uploaded_files:\n",
        "    print(\"‚ö†Ô∏è Please upload at least one resume file.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Uploaded {len(uploaded_files)} file(s)\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "eWUzNhnrMRU9",
        "outputId": "414173ea-ad0e-4233-d15c-77da53362e54"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Please upload resume files (PDF or DOCX):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95cb3ffd-42cb-4862-b690-916c24fbcd61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95cb3ffd-42cb-4862-b690-916c24fbcd61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ANUSREE-K-AI DEVELOPER_RESUME.pdf to ANUSREE-K-AI DEVELOPER_RESUME (1).pdf\n",
            "‚úÖ Uploaded 1 file(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîÑ Initializing resume processor...\")\n",
        "processor = ResumeProcessor()\n",
        "candidates = []\n",
        "\n",
        "for filename, file_content in uploaded_files.items():\n",
        "    print(f\"üîç Processing {filename}...\")\n",
        "    candidate = processor.process_resume(file_content, filename, jd)\n",
        "    if candidate:\n",
        "        candidates.append(candidate)\n",
        "        print(f\"   ‚úÖ Processed: {candidate.name} - Score: {candidate.score}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Failed to process: {filename}\")\n",
        "\n",
        "# Sort candidates by score\n",
        "candidates.sort(key=lambda x: x.score, reverse=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZk14U7uMVeD",
        "outputId": "17c29292-3f13-401b-e475-5473d94255fa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Initializing resume processor...\n",
            "üîÑ Loading free NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ NLP models initialized\n",
            "üîç Processing ANUSREE-K-AI DEVELOPER_RESUME (1).pdf...\n",
            "   ‚úÖ Processed: Unknown Candidate - Score: 71.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f\"<h2>üèÜ Ranked Candidates ({len(candidates)} found)</h2>\"))\n",
        "\n",
        "if not candidates:\n",
        "    print(\"‚ùå No candidates processed successfully. Check your file formats.\")\n",
        "else:\n",
        "    for i, candidate in enumerate(candidates, 1):\n",
        "        display(HTML(f\"<h3>#{i} - Score: {candidate.score:.1f}/100</h3>\"))\n",
        "        candidate.display()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "nhZro0AaMdU_",
        "outputId": "16c87a8c-b260-4c78-a6ee-842e776439b1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>üèÜ Ranked Candidates (1 found)</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>#1 - Score: 71.5/100</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"border: 2px solid #e0e0e0; padding: 15px; margin: 10px; border-radius: 10px; background: #f9f9f9;\">\n",
              "            <h3>üë§ Unknown Candidate - Score: 71.5/100</h3>\n",
              "            <p><strong>üìß Email:</strong> kanusreek5@gmail.com</p>\n",
              "            <p><strong>üìã Summary:</strong>  Anusree Kaunusreek 5@gmail.com 8157825339 Kuttiyil house,Eramala(po),Vatakara(via),673501 . He is an AI developer with expertise in machine learning, deep learning, and natural language processing .</p>\n",
              "            <p><strong>üõ†Ô∏è Skills:</strong> numpy, aws, go, tensorflow, seaborn, python, git, scikit, sql, matplotlib...</p>\n",
              "            <p><strong>üíº Experience Highlight:</strong> experience in geographic information systems and \n",
              "disaster management.\n",
              "skills summary\n",
              "frameworks / libraries\n",
              "tensorflow/keras, scikit-learn, opencv, \n",
              "......</p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = min(3, len(candidates))  # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "if candidates:\n",
        "    selected_candidates = candidates[:top_n]\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"background: #4caf50; color: white; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
        "        <h2>‚úÖ Selected Top {top_n} Candidates</h2>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    for i, candidate in enumerate(selected_candidates, 1):\n",
        "        display(HTML(f\"<h3>#{i} - {candidate.name} ({candidate.score:.1f})</h3>\"))\n",
        "        candidate.display()\n",
        "\n",
        "    # @title ### **11. Generate Interview Schedule**\n",
        "    display(HTML(\"<h2>üìÖ Proposed Interview Schedule</h2>\"))\n",
        "\n",
        "    # Generate interview times (next business days at 10 AM)\n",
        "    interview_times = []\n",
        "    current_date = datetime.now()\n",
        "    for i in range(len(selected_candidates)):\n",
        "        # Skip weekends\n",
        "        while current_date.weekday() >= 5:  # 5=Saturday, 6=Sunday\n",
        "            current_date += timedelta(days=1)\n",
        "\n",
        "        interview_time = current_date.replace(hour=10, minute=0, second=0, microsecond=0)\n",
        "        interview_times.append(interview_time)\n",
        "        current_date += timedelta(days=1)\n",
        "\n",
        "    for candidate, interview_time in zip(selected_candidates, interview_times):\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"border: 1px solid #ccc; padding: 15px; margin: 10px; border-radius: 5px;\">\n",
        "            <h4>üë§ {candidate.name}</h4>\n",
        "            <p>üìß {candidate.email}</p>\n",
        "            <p>üìÖ <strong>Proposed Interview:</strong> {interview_time.strftime('%A, %B %d, %Y at %I:%M %p')}</p>\n",
        "            <p>üîó <em>Calendar integration ready for production use</em></p>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "else:\n",
        "    print(\"‚ùå No candidates to select\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "rcwsjKGMMeHA",
        "outputId": "0210522b-b562-41fc-cdc5-d54528c51918"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: #4caf50; color: white; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
              "        <h2>‚úÖ Selected Top 1 Candidates</h2>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>#1 - Unknown Candidate (71.5)</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"border: 2px solid #e0e0e0; padding: 15px; margin: 10px; border-radius: 10px; background: #f9f9f9;\">\n",
              "            <h3>üë§ Unknown Candidate - Score: 71.5/100</h3>\n",
              "            <p><strong>üìß Email:</strong> kanusreek5@gmail.com</p>\n",
              "            <p><strong>üìã Summary:</strong>  Anusree Kaunusreek 5@gmail.com 8157825339 Kuttiyil house,Eramala(po),Vatakara(via),673501 . He is an AI developer with expertise in machine learning, deep learning, and natural language processing .</p>\n",
              "            <p><strong>üõ†Ô∏è Skills:</strong> numpy, aws, go, tensorflow, seaborn, python, git, scikit, sql, matplotlib...</p>\n",
              "            <p><strong>üíº Experience Highlight:</strong> experience in geographic information systems and \n",
              "disaster management.\n",
              "skills summary\n",
              "frameworks / libraries\n",
              "tensorflow/keras, scikit-learn, opencv, \n",
              "......</p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>üìÖ Proposed Interview Schedule</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"border: 1px solid #ccc; padding: 15px; margin: 10px; border-radius: 5px;\">\n",
              "            <h4>üë§ Unknown Candidate</h4>\n",
              "            <p>üìß kanusreek5@gmail.com</p>\n",
              "            <p>üìÖ <strong>Proposed Interview:</strong> Monday, August 25, 2025 at 10:00 AM</p>\n",
              "            <p>üîó <em>Calendar integration ready for production use</em></p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if candidates:\n",
        "    results = {\n",
        "        \"job_description\": jd.to_dict(),\n",
        "        \"processing_date\": datetime.now().isoformat(),\n",
        "        \"candidates\": [\n",
        "            {\n",
        "                \"id\": c.id,\n",
        "                \"name\": c.name,\n",
        "                \"email\": c.email,\n",
        "                \"score\": c.score,\n",
        "                \"summary\": c.summary,\n",
        "                \"skills\": c.skills,\n",
        "                \"selected\": i < top_n\n",
        "            }\n",
        "            for i, c in enumerate(candidates)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create downloadable file\n",
        "    json_str = json.dumps(results, indent=2)\n",
        "    filename = 'candidate_analysis_results.json'\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(json_str)\n",
        "\n",
        "    files.download(filename)\n",
        "    print(\"‚úÖ Results exported as candidate_analysis_results.json\")\n",
        "else:\n",
        "    print(\"‚ùå No results to export\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "g2ToWYQWMeKG",
        "outputId": "b80e3263-9242-45c3-9fed-689d69f734d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5b562954-fb97-48e6-9318-fa576723adce\", \"candidate_analysis_results.json\", 1378)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Results exported as candidate_analysis_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZV1dyj-MeNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4J-ALROlMeQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SyRODbPuMeUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LY27GasKMeXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdGxpYHKMebC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wp4Ijh8FMeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFT1xxKPMeiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEVGSIDQMelh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBYsWk1MMesc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}